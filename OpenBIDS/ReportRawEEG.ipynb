{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "64d9ea56-43da-4708-8c48-c1a24b4d0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import cmlreaders as cml\n",
    "from cmldask import CMLDask as da\n",
    "from dask.distributed import wait, as_completed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy as scp\n",
    "import re\n",
    "from scipy import stats\n",
    "from ptsa.data.timeseries import *\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pyedflib\n",
    "from mne_bids import get_entity_vals\n",
    "from ReportRawEEG import *\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 50\n",
    "%matplotlib inline\n",
    "import mne\n",
    "from mne_bids import BIDSPath, read_raw_bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b1dfae4-1776-4f7d-b455-3e9027cbfb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['LTP606', 'LTP607', 'LTP609', 'LTP610', 'LTP612']\n",
    "experiment = 'valuecourier'\n",
    "bids_root = \"/home1/maint/LTP_BIDS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "195267ae-7060-4ad8-89d0-8d01635479a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "def fix_evs_bids(full_evs):\n",
    "    value_recalls = full_evs[full_evs.trial_type == \"VALUE_RECALL\"] \n",
    "    words = full_evs[full_evs.trial_type == \"WORD\"]\n",
    "    rec_words = full_evs[full_evs.trial_type == \"REC_WORD\"]\n",
    "    rec_vv_words = full_evs[full_evs.trial_type == \"REC_WORD_VV\"]\n",
    "\n",
    "    # WORD --> storepointtype, recalled--> VALUE_RECALL, REC_WORD, REC_WORD_VV\n",
    "    word_trial_to_storepointtype = words.set_index(\"trial\")[\"storepointtype\"].to_dict()\n",
    "    word_trial_to_recalled = words.set_index(\"trial\")[\"recalled\"].to_dict()\n",
    "    for event_type in [\"VALUE_RECALL\", \"REC_WORD\", \"REC_WORD_VV\"]:\n",
    "        subset = full_evs[full_evs.trial_type == event_type]\n",
    "        for idx, row in subset.iterrows():\n",
    "            trial = row[\"trial\"]\n",
    "            if trial in word_trial_to_storepointtype:\n",
    "                full_evs.at[idx, \"storepointtype\"] = word_trial_to_storepointtype[trial]\n",
    "            if trial in word_trial_to_recalled:\n",
    "                full_evs.at[idx, \"recalled\"] = word_trial_to_recalled[trial]\n",
    "\n",
    "    # VALUE_RECALL --> actualvalue, valuerecall --> WORD, `REC_WORD`, REC_WORD_VV\n",
    "    valuerecall_trial_to_actualvalue = value_recalls.set_index(\"trial\")[\"actualvalue\"].to_dict()\n",
    "    valuerecall_trial_to_valuerecall = value_recalls.set_index(\"trial\")[\"valuerecall\"].to_dict()\n",
    "\n",
    "    # --- Apply to multi-row event types ---\n",
    "    for event_type in [\"WORD\", \"REC_WORD\", \"REC_WORD_VV\"]:\n",
    "        subset = full_evs[full_evs.trial_type == event_type]\n",
    "        for idx, row in subset.iterrows():\n",
    "            trial = row[\"trial\"]\n",
    "\n",
    "            # actualvalue\n",
    "            if trial in valuerecall_trial_to_actualvalue:\n",
    "                full_evs.at[idx, \"actualvalue\"] = valuerecall_trial_to_actualvalue[trial]\n",
    "\n",
    "            # valuerecall\n",
    "            if trial in valuerecall_trial_to_valuerecall:\n",
    "                full_evs.at[idx, \"valuerecall\"] = valuerecall_trial_to_valuerecall[trial]\n",
    "                \n",
    "    return full_evs\n",
    "\n",
    "def fix_evs_cml(full_evs):\n",
    "    value_recalls = full_evs[full_evs.type == \"VALUE_RECALL\"] \n",
    "    words = full_evs[full_evs.type == \"WORD\"]\n",
    "    rec_words = full_evs[full_evs.type == \"REC_WORD\"]\n",
    "    rec_vv_words = full_evs[full_evs.type == \"REC_WORD_VV\"]\n",
    "\n",
    "    # WORD --> storepointtype, recalled--> VALUE_RECALL, REC_WORD, REC_WORD_VV\n",
    "    word_trial_to_storepointtype = words.set_index(\"trial\")[\"storepointtype\"].to_dict()\n",
    "    word_trial_to_recalled = words.set_index(\"trial\")[\"recalled\"].to_dict()\n",
    "    for event_type in [\"VALUE_RECALL\", \"REC_WORD\", \"REC_WORD_VV\"]:\n",
    "        subset = full_evs[full_evs.type == event_type]\n",
    "        for idx, row in subset.iterrows():\n",
    "            trial = row[\"trial\"]\n",
    "            if trial in word_trial_to_storepointtype:\n",
    "                full_evs.at[idx, \"storepointtype\"] = word_trial_to_storepointtype[trial]\n",
    "            if trial in word_trial_to_recalled:\n",
    "                full_evs.at[idx, \"recalled\"] = word_trial_to_recalled[trial]\n",
    "\n",
    "    # VALUE_RECALL --> actualvalue, valuerecall --> WORD, `REC_WORD`, REC_WORD_VV\n",
    "    valuerecall_trial_to_actualvalue = value_recalls.set_index(\"trial\")[\"actualvalue\"].to_dict()\n",
    "    valuerecall_trial_to_valuerecall = value_recalls.set_index(\"trial\")[\"valuerecall\"].to_dict()\n",
    "\n",
    "    # --- Apply to multi-row event types ---\n",
    "    for event_type in [\"WORD\", \"REC_WORD\", \"REC_WORD_VV\"]:\n",
    "        subset = full_evs[full_evs.type == event_type]\n",
    "        for idx, row in subset.iterrows():\n",
    "            trial = row[\"trial\"]\n",
    "\n",
    "            # actualvalue\n",
    "            if trial in valuerecall_trial_to_actualvalue:\n",
    "                full_evs.at[idx, \"actualvalue\"] = valuerecall_trial_to_actualvalue[trial]\n",
    "\n",
    "            # valuerecall\n",
    "            if trial in valuerecall_trial_to_valuerecall:\n",
    "                full_evs.at[idx, \"valuerecall\"] = valuerecall_trial_to_valuerecall[trial]\n",
    "                \n",
    "    return full_evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08322b95-a45e-4358-8beb-84d9eab899f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sess = 0\n",
    "# subject = \"LTP606\"\n",
    "# ### Compare BIDS vs CML Reader\n",
    "# bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "# # 1 subject\n",
    "# # events\n",
    "# # CML\n",
    "# reader = cml.CMLReader(subject=subject, experiment=\"ValueCourier\", session=sess)\n",
    "# evs_cml = reader.load('events')\n",
    "# evs_cml = fix_evs_cml(evs_cml)\n",
    "# # evs_cml = evs_cml[(evs_cml['type']=='WORD') & (evs_cml['eegoffset']>=0)]\n",
    "\n",
    "# # BIDS\n",
    "# bids_path = BIDSPath(\n",
    "#     subject=subject,\n",
    "#     session=str(sess),\n",
    "#     task=\"valuecourier\",\n",
    "#     datatype=\"eeg\",\n",
    "#     root=bids_root,\n",
    "# )\n",
    "\n",
    "# # --------------------------\n",
    "# # Load BIDS events.tsv\n",
    "# # --------------------------\n",
    "# events_path = os.path.join(bids_path.directory, bids_path.basename + \"_events.tsv\")\n",
    "# evs_bids = pd.read_csv(events_path, sep=\"\\t\")\n",
    "# evs_bids = fix_evs_bids(evs_bids)\n",
    "\n",
    "# # evs_bids = evs_bids.query(\"trial_type == 'WORD' and sample >= 0\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "783809e2-a2fc-4b5d-9456-1e61a1cc2d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# res = compare_behavioral(\n",
    "#     evs_cml, \"CMLReader\",\n",
    "#     evs_bids, \"OpenBIDS\",\n",
    "#     options=[\n",
    "#         \"compare_onset_as_diff\",\n",
    "#         \"tolerant_numeric\",\n",
    "#         \"print_behavior_summary\",\n",
    "#         \"print_behavior_col_summary\",\n",
    "#         \"print_behavior_mismatches\",\n",
    "#         \"return_col_summary\",\n",
    "#         \"return_mismatches\",\n",
    "#     ],\n",
    "#     drop_cols=[],  # add stuff you explicitly don't want compared\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8ebe342-4379-4096-832d-5d4a930a6c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # check eeg\n",
    "# # CML\n",
    "# eeg_cml = reader.load_eeg().to_ptsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a10d3b38-ecef-407f-b996-9e52d7a566f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # bids\n",
    "# REL_START, REL_STOP = 200 /1000, 3000 /1000\n",
    "# BUFFER_MS = 1000 /1000\n",
    "# WIDTH = 6\n",
    "\n",
    "# FREQS = np.logspace(np.log10(2), np.log10(100), 46)\n",
    "# NOTCH_BAND = (58., 62.)\n",
    "# BATCH_EVENTS = 64\n",
    "\n",
    "# bids_path = BIDSPath(\n",
    "#     subject=\"LTP606\",\n",
    "#     session=str(0),\n",
    "#     task=\"valuecourier\",\n",
    "#     datatype=\"eeg\",\n",
    "#     root=bids_root,\n",
    "# )\n",
    " \n",
    "# raw = read_raw_bids(bids_path)\n",
    "\n",
    "# raw.set_channel_types({\n",
    "#     \"EXG1\": \"eog\", \"EXG2\": \"eog\", \"EXG3\": \"eog\", \"EXG4\": \"eog\",\n",
    "#     \"EXG5\": \"misc\", \"EXG6\": \"misc\", \"EXG7\": \"misc\", \"EXG8\": \"misc\",\n",
    "# })\n",
    "\n",
    "# # raw.drop_channels(\n",
    "# #     [ch for ch in raw.ch_names if raw.get_channel_types(picks=ch)[0] != \"eeg\"]\n",
    "# # )\n",
    "\n",
    "# # --------------------------\n",
    "# # Epoch WORD events from annotations\n",
    "# # --------------------------\n",
    "# events, event_id = mne.events_from_annotations(raw)\n",
    "# word_event_id = {k: v for k, v in event_id.items() if (k == \"WORD\")}\n",
    "\n",
    "# # ---- CRITICAL: MNE expects SECONDS ----\n",
    "# # If your constants are in ms, convert here:\n",
    "# tmin = (-BUFFER_MS)\n",
    "# tmax = ((REL_STOP + BUFFER_MS))\n",
    "\n",
    "# epochs_bids = mne.Epochs(\n",
    "#     raw,\n",
    "#     events=events,\n",
    "#     event_id=word_event_id,\n",
    "#     tmin=tmin,\n",
    "#     tmax=tmax,\n",
    "#     baseline=(None, 0),\n",
    "#     preload=True,\n",
    "#     event_repeated=\"merge\",\n",
    "# )\n",
    "\n",
    "# print(\"sfreq:\", epochs_bids.info[\"sfreq\"])\n",
    "# print(\"tmin,tmax:\", epochs_bids.tmin, epochs_bids.tmax)\n",
    "# print(\"n_times:\", len(epochs_bids.times))\n",
    "# print(\"duration_s:\", epochs_bids.times[-1] - epochs_bids.times[0])\n",
    "\n",
    "# eeg_bids = TimeSeries.from_mne_epochs(epochs_bids, evs_bids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa3005ff-a957-4073-b28f-f2ab01c8f435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw = read_raw_bids(\n",
    "#     bids_path,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# eeg_bids = xr.DataArray(\n",
    "#     raw.get_data()[None, :, :],                           # -> (1, n_channels, n_times)\n",
    "#     dims=(\"event\", \"channel\", \"time\"),         # match eeg_cml dim names\n",
    "#     coords={\n",
    "#         \"event\": [0],                          # singleton event index\n",
    "#         \"channel\": raw.ch_names,\n",
    "#         \"time\": raw.times  ,\n",
    "#         \"samplerate\": raw.info[\"sfreq\"],                    # scalar coord (optional)\n",
    "#     },\n",
    "#     name=\"eeg\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9f47b2d4-1ff8-44a4-93c1-7e3f39e2533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### ACROSS MULTIPLE SUBJECTS AND SESSIONS\n",
    "bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "subjects = get_entity_vals(bids_root, \"subject\")\n",
    "\n",
    "\n",
    "# subject\n",
    "def process_raw_signals(sub, exp, sess, bids_root, out_path): # entire signal, not epoched\n",
    "    ### load cml\n",
    "    reader = cml.CMLReader(subject=sub, experiment=exp, session=sess)\n",
    "    eeg_cml = reader.load_eeg().to_ptsa()\n",
    "\n",
    "    ### load bdf\n",
    "    # BIDS\n",
    "    bids_path = BIDSPath(\n",
    "        subject=sub,\n",
    "        session=str(sess),\n",
    "        task=exp.lower(),\n",
    "        datatype=\"eeg\",\n",
    "        root=bids_root,\n",
    "    )\n",
    "\n",
    "    raw = read_raw_bids(\n",
    "        bids_path,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    eeg_bids = xr.DataArray(\n",
    "        raw.get_data()[None, :, :],                           # -> (1, n_channels, n_times)\n",
    "        dims=(\"event\", \"channel\", \"time\"),         # match eeg_cml dim names\n",
    "        coords={\n",
    "            \"event\": [0],                          # singleton event index\n",
    "            \"channel\": raw.ch_names,\n",
    "            \"time\": raw.times * 1000,\n",
    "            \"samplerate\": raw.info[\"sfreq\"],                    # scalar coord (optional)\n",
    "        },\n",
    "        name=\"eeg\",\n",
    "    )\n",
    "    \n",
    "    # return eeg_cml, eeg_bids\n",
    "    \n",
    "\n",
    "    ## load pyedf\n",
    "    # cml_bdf_path  = f\"/protocols/ltp/subjects/{sub}/experiments/{exp}/sessions/{sess}/ephys/current_processed/{sub}_session_{sess}.bdf\"\n",
    "    # eeg_pyedflib = load_bdf_as_xarray(cml_bdf_path)\n",
    "\n",
    "    # compare\n",
    "    results = compare_eeg_sources(\n",
    "        eeg_dict={\"BIDS\": eeg_bids, \"CMLReader\": eeg_cml},\n",
    "        subject=sub,\n",
    "        experiment=exp,\n",
    "        session=sess,\n",
    "        options=[\"strip_metadata\", \"compare_raw_signals\", \"compare_time_coords\"]\n",
    "    )\n",
    "    \n",
    "    results[\"df_raw\"].to_csv(f\"{out_path}df_raw_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "    results[\"df_raw_summary\"].to_csv(f\"{out_path}df_raw_summary_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "    results[\"df_time\"].to_csv(f\"{out_path}df_time_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64b187b9-db7c-4a77-b204-155ce2913f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eeg_cml, eeg_bids = process_raw_signals(\"LTP606\", \"ValueCourier\", 0, \"/home1/maint/LTP_BIDS/\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45355f54-4e98-4b45-8c3a-541d7555dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _all_exist(paths):\n",
    "    return all(os.path.exists(p) for p in paths)\n",
    "\n",
    "def process_events(sub, exp, sess, evs_types,bids_root, out_path, *, skip_if_exists=True):\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    out_behavior_summary = os.path.join(out_path, f\"df_behavior_summary_{sub}_{exp}_{sess}.csv\")\n",
    "    # Uncomment these if you re-enable writing them:\n",
    "    # out_behavior_col = os.path.join(out_path, f\"df_behavior_column_summary_{sub}_{exp}_{sess}.csv\")\n",
    "    # out_behavior_mismatch = os.path.join(out_path, f\"df_behavior_mismatches_{sub}_{exp}_{sess}.csv\")\n",
    "    expected = [out_behavior_summary]\n",
    "\n",
    "    if skip_if_exists and _all_exist(expected):\n",
    "        return {\"skipped\": True, \"reason\": \"outputs_exist\", \"paths\": expected}\n",
    "    ### load cml\n",
    "    cmlreader = cml.CMLReader(subject=sub, experiment=exp, session=sess)\n",
    "    evs_cml = cmlreader.load('events')\n",
    "    \n",
    "    evs_types_set = set(evs_types) if evs_types is not None else set(evs_cml[\"type\"].unique())\n",
    "    # print(evs_types_set)\n",
    "    if exp == \"ValueCourier\":\n",
    "        evs_cml = fix_evs_cml(evs_cml)\n",
    "    \n",
    "    filtered_evs_cml = evs_cml[evs_cml[\"type\"].isin(evs_types_set)]\n",
    "    \n",
    "    exp_lower = exp\n",
    "    exp_lower = exp_lower.lower()\n",
    "    path_bids = BIDSPath(\n",
    "                subject=sub,\n",
    "                session=str(sess),\n",
    "                task=exp_lower,  \n",
    "                datatype=\"beh\", \n",
    "                suffix=\"beh\",\n",
    "                extension=\".tsv\",\n",
    "                root=bids_root\n",
    "            )\n",
    "    evs_bids = pd.read_csv(path_bids.fpath, sep=\"\\t\")\n",
    "    # bids_path = BIDSPath(\n",
    "    #     subject=sub,\n",
    "    #     session=str(sess),\n",
    "    #     task=exp_lower,\n",
    "    #     datatype=\"eeg\",\n",
    "    #     root=bids_root,\n",
    "    # )\n",
    "\n",
    "#     # --------------------------\n",
    "#     # Load BIDS events.tsv\n",
    "#     # --------------------------\n",
    "#     events_path = os.path.join(bids_path.directory, bids_path.basename + \"_events.tsv\")\n",
    "#     evs_bids = pd.read_csv(events_path, sep=\"\\t\")\n",
    "    if exp == \"ValueCourier\":\n",
    "        evs_bids = fix_evs_bids(evs_bids)\n",
    "\n",
    "    filtered_evs_bids = evs_bids[evs_bids[\"trial_type\"].isin(evs_types_set)]\n",
    "    if filtered_evs_bids.empty:\n",
    "        raise ValueError(\"Filtered events dataframe has no rows\")\n",
    "    try: \n",
    "        results = compare_behavioral(\n",
    "            evs_cml, \"CMLReader\",\n",
    "            evs_bids, \"OpenBIDS\",\n",
    "            options=[\n",
    "                \"compare_onset_as_diff\",\n",
    "                \"tolerant_numeric\",\n",
    "                \"return_col_summary\",\n",
    "                \"return_mismatches\",\n",
    "            ],\n",
    "            drop_cols=[],  # add stuff you explicitly don't want compared\n",
    "        )\n",
    "        # results[\"df_behavior_summary\"].to_csv(f\"{out_path}df_behavior_summary{sub}_{exp}_{sess}.csv\", index=False)\n",
    "        # results[\"df_behavior_column_summary\"].to_csv(f\"{out_path}df_behavior_column_summary_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "        # results[\"df_behavior_mismatches\"].to_csv(f\"{out_path}df_behavior_mismatches_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "        results[\"df_behavior_summary\"].to_csv(\n",
    "            os.path.join(out_path, f\"df_behavior_summary_{sub}_{exp}_{sess}.csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        # results[\"df_behavior_column_summary\"].to_csv(\n",
    "        #     os.path.join(out_path, f\"df_behavior_column_summary_{sub}_{exp}_{sess}.csv\"),\n",
    "        #     index=False,\n",
    "        # )\n",
    "        # results[\"df_behavior_mismatches\"].to_csv(\n",
    "        #     os.path.join(out_path, f\"df_behavior_mismatches_{sub}_{exp}_{sess}.csv\"),\n",
    "        #     index=False,\n",
    "        # )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Failed process_events: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d8ff62df-848d-41b3-ae69-fad32fc6d9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# process_events(\"LTP606\", \"ValueCourier\", 0, None, \"/home1/maint/LTP_BIDS/\", \"raw_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666eb10-5e9d-4357-a210-494657f14ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne_bids import get_entity_vals\n",
    "# from ReportRawEEG import *\n",
    "# ### ACROSS MULTIPLE SUBJECTS AND SESSIONS\n",
    "# bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "# subjects = get_entity_vals(bids_root, \"subject\")\n",
    "\n",
    "\n",
    "# # subject\n",
    "# def process_epoched_signals(sub, exp, sess, evs_types,  tmin, tmax, bids_root, out_path):\n",
    "#     ### load cml\n",
    "#     cmlreader = cml.CMLReader(subject=sub, experiment=exp, session=sess)\n",
    "#     evs_cml = cmlreader.load('events')\n",
    "    \n",
    "#     if evs_types is None:\n",
    "#         evs_types_set = set(evs_cml[\"type\"].unique())\n",
    "#     else:\n",
    "#         evs_types_set = set(evs_types)\n",
    "    \n",
    "    \n",
    "#     filtered_evs_cml = evs_cml[evs_cml[\"type\"].isin(evs_types_set)]\n",
    "    \n",
    "#     eeg_cml = cmlreader.load_eeg(filtered_evs_cml, rel_start=tmin, rel_stop=tmax).to_ptsa()\n",
    "    \n",
    "    \n",
    "#     exp_lower = exp\n",
    "#     exp_lower = exp_lower.lower()\n",
    "#     ### load events\n",
    "#     # path_bids = BIDSPath(\n",
    "#     #             subject=sub,\n",
    "#     #             session=str(sess),\n",
    "#     #             task=exp_lower,  \n",
    "#     #             datatype=\"beh\", \n",
    "#     #             suffix=\"beh\",\n",
    "#     #             extension=\".tsv\",\n",
    "#     #             root=bids_root\n",
    "#     #         )\n",
    "#     # evs_bids = pd.read_csv(path_bids.fpath, sep=\"\\t\")\n",
    "\n",
    "# #     # --------------------------\n",
    "# #     # Load BIDS events.tsv\n",
    "# #     # --------------------------\n",
    "#     bids_path = BIDSPath(\n",
    "#         subject=sub,\n",
    "#         session=str(sess),\n",
    "#         task=exp_lower,\n",
    "#         datatype=\"eeg\",\n",
    "#         root=bids_root,\n",
    "#     )\n",
    "#     events_path = os.path.join(bids_path.directory, bids_path.basename + \"_events.tsv\")\n",
    "#     evs_bids = pd.read_csv(events_path, sep=\"\\t\")\n",
    "#     if exp == \"ValueCourier\":\n",
    "#         evs_bids = fix_evs_bids(evs_bids)\n",
    "\n",
    "#     filtered_evs_bids = evs_bids[evs_bids[\"trial_type\"].isin(evs_types_set)]\n",
    "#     if filtered_evs_bids.empty:\n",
    "#         raise ValueError(\"Filtered events dataframe has no rows\")\n",
    "\n",
    "#     raw_bids = read_raw_bids(bids_path)\n",
    "\n",
    "#     raw_bids.set_channel_types({\n",
    "#         \"EXG1\": \"eog\", \"EXG2\": \"eog\", \"EXG3\": \"eog\", \"EXG4\": \"eog\",\n",
    "#         \"EXG5\": \"misc\", \"EXG6\": \"misc\", \"EXG7\": \"misc\", \"EXG8\": \"misc\",\n",
    "#     })\n",
    "\n",
    "#     # --------------------------\n",
    "#     # Epoch WORD events from annotations\n",
    "#     # --------------------------\n",
    "#     events_bids, event_bids_id = mne.events_from_annotations(raw_bids)\n",
    "#     filtered_event_bids_id = {k: v for k, v in event_bids_id.items() if (k in evs_types_set)}\n",
    "#     if not filtered_event_bids_id:\n",
    "#         raise ValueError(\"Filtered events id has no ids\")\n",
    "#     try: \n",
    "#         epochs_bids = mne.Epochs(\n",
    "#             raw_bids,\n",
    "#             events=events_bids,\n",
    "#             event_id=filtered_event_bids_id,\n",
    "#             tmin=tmin / 1000,\n",
    "#             tmax=tmax / 1000,\n",
    "#             baseline=None,\n",
    "#             preload=True,\n",
    "#             event_repeated=\"drop\",\n",
    "#         )\n",
    "#         # del raw_bids, event_bids\n",
    "\n",
    "#         # We only need EEG channels (exclude eog/misc)\n",
    "#         picks_eeg = mne.pick_types(epochs_bids.info, eeg=True, eog=False, misc=False)\n",
    "#         epochs_bids = epochs_bids.pick(picks_eeg)\n",
    "\n",
    "#         eeg_bids = TimeSeries.from_mne_epochs(epochs_bids, filtered_evs_bids)\n",
    "#         eeg_bids = eeg_bids.assign_coords(time=eeg_bids[\"time\"] * 1000)\n",
    "#         eeg_bids[\"time\"].attrs[\"units\"] = \"ms\"\n",
    "\n",
    "#         print(eeg_bids.time.data)\n",
    "#         # del epochs_bids\n",
    "#         # compare\n",
    "#         results = compare_eeg_sources(\n",
    "#             eeg_dict={\"BIDS\": eeg_bids, \"CMLReader\": eeg_cml},\n",
    "#             subject=sub,\n",
    "#             experiment=exp,\n",
    "#             session=sess,\n",
    "#             options=[\"strip_metadata\", \"compare_raw_signals\", \"compare_time_coords\"]\n",
    "#         )\n",
    "#         os.makedirs(out_path, exist_ok=True)\n",
    "#         results[\"df_raw\"].to_csv(f\"{out_path}df_raw_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "#         results[\"df_raw_summary\"].to_csv(f\"{out_path}df_raw_summary_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "#         results[\"df_time\"].to_csv(f\"{out_path}df_time_{sub}_{exp}_{sess}.csv\", index=False)\n",
    "#         return results\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed process_epoched_signals by failing to load EEG data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5e0971bf-7374-4320-acb8-b819e6ac92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_bids import BIDSPath\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from ReportRawEEG import *\n",
    "\n",
    "def _all_exist(paths):\n",
    "    return all(os.path.exists(p) for p in paths)\n",
    "\n",
    "def _dedupe_events_by_sample(df: pd.DataFrame, sample_col: str, *, keep=\"first\") -> pd.DataFrame:\n",
    "    if sample_col not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{sample_col}' in events df. Columns={list(df.columns)[:20]}\")\n",
    "    df2 = df.copy()\n",
    "    df2[sample_col] = pd.to_numeric(df2[sample_col], errors=\"coerce\")\n",
    "    df2 = df2.dropna(subset=[sample_col])\n",
    "    df2 = df2.sort_values(sample_col, kind=\"mergesort\")\n",
    "    df2 = df2[~df2[sample_col].duplicated(keep=keep)]\n",
    "    return df2\n",
    "\n",
    "def _as_list(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    if isinstance(x, (list, tuple, set, np.ndarray, pd.Index)):\n",
    "        return list(x)\n",
    "    return [x]\n",
    "\n",
    "def process_epoched_signals_by_type(\n",
    "    sub,\n",
    "    exp,\n",
    "    sess,\n",
    "    evs_types,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    bids_root,\n",
    "    out_path,\n",
    "    *,\n",
    "    skip_if_exists=True,\n",
    "    keep=\"first\",\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run epoch+compare separately for each event type, append results across types,\n",
    "    save and return the appended DataFrames.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    # aggregated outputs (ONE set per sub/exp/sess)\n",
    "    out_raw = os.path.join(out_path, f\"df_raw_{sub}_{exp}_{sess}.csv\")\n",
    "    out_raw_summary = os.path.join(out_path, f\"df_raw_summary_{sub}_{exp}_{sess}.csv\")\n",
    "    out_time = os.path.join(out_path, f\"df_time_{sub}_{exp}_{sess}.csv\")\n",
    "    expected = [out_raw, out_raw_summary, out_time]\n",
    "\n",
    "    if skip_if_exists and _all_exist(expected):\n",
    "        print(\"Files exist: skipped\")\n",
    "        return {\"skipped\": True, \"reason\": \"outputs_exist\", \"paths\": expected}\n",
    "\n",
    "    # --------------------------\n",
    "    # CML: load events once\n",
    "    # --------------------------\n",
    "    cmlreader = cml.CMLReader(subject=sub, experiment=exp, session=sess)\n",
    "    evs_cml = cmlreader.load(\"events\")\n",
    "\n",
    "    # decide which types to run\n",
    "    if evs_types is None:\n",
    "        types_to_run = sorted(pd.unique(evs_cml[\"type\"]))\n",
    "    else:\n",
    "        types_to_run = sorted(set(_as_list(evs_types)))\n",
    "\n",
    "    if len(types_to_run) == 0:\n",
    "        raise ValueError(\"types_to_run is empty.\")\n",
    "\n",
    "    # --------------------------\n",
    "    # BIDS: load raw + annotations once\n",
    "    # --------------------------\n",
    "    task = exp.lower()\n",
    "    bids_path = BIDSPath(\n",
    "        subject=sub,\n",
    "        session=str(sess),\n",
    "        task=task,\n",
    "        datatype=\"eeg\",\n",
    "        root=bids_root,\n",
    "    )\n",
    "\n",
    "    raw_bids = read_raw_bids(bids_path)\n",
    "    raw_bids.set_channel_types({\n",
    "        \"EXG1\": \"eog\", \"EXG2\": \"eog\", \"EXG3\": \"eog\", \"EXG4\": \"eog\",\n",
    "        \"EXG5\": \"misc\", \"EXG6\": \"misc\", \"EXG7\": \"misc\", \"EXG8\": \"misc\",\n",
    "    })\n",
    "\n",
    "    events_all, event_id_all = mne.events_from_annotations(raw_bids)\n",
    "    sfreq = float(raw_bids.info[\"sfreq\"])\n",
    "\n",
    "    # collect per-type outputs\n",
    "    all_raw = []\n",
    "    all_raw_summary = []\n",
    "    all_time = []\n",
    "\n",
    "    # optional bookkeeping\n",
    "    per_type_status = []\n",
    "\n",
    "    for etype in types_to_run:\n",
    "        if verbose:\n",
    "            print(f\"[{sub} | {exp} | {sess}] type={etype}\")\n",
    "\n",
    "        try:\n",
    "            # --------------------------\n",
    "            # CML: filter to this type + dedupe by eegoffset, then epoch\n",
    "            # --------------------------\n",
    "            evs_cml_t = evs_cml[evs_cml[\"type\"] == etype].copy()\n",
    "            if evs_cml_t.empty:\n",
    "                per_type_status.append((etype, \"skip\", \"no_cml_events\"))\n",
    "                continue\n",
    "\n",
    "            evs_cml_t = _dedupe_events_by_sample(evs_cml_t, \"eegoffset\", keep=keep)\n",
    "\n",
    "            eeg_cml = cmlreader.load_eeg(evs_cml_t, rel_start=tmin, rel_stop=tmax).to_ptsa()\n",
    "\n",
    "            # --------------------------\n",
    "            # BIDS: filter annotation labels/codes for this type, dedupe by sample, epoch\n",
    "            # --------------------------\n",
    "            if etype not in event_id_all:\n",
    "                per_type_status.append((etype, \"skip\", \"etype_not_in_annotations\"))\n",
    "                # free CML epoch before continue\n",
    "                del eeg_cml\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "            filtered_event_id = {etype: event_id_all[etype]}\n",
    "            code = filtered_event_id[etype]\n",
    "\n",
    "            events_filt = events_all[events_all[:, 2] == code]\n",
    "            if len(events_filt) == 0:\n",
    "                per_type_status.append((etype, \"skip\", \"no_bids_events\"))\n",
    "                del eeg_cml\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "            # dedupe by sample\n",
    "            _, first_idx = np.unique(events_filt[:, 0], return_index=True)\n",
    "            events_filt = events_filt[np.sort(first_idx)]\n",
    "\n",
    "            epochs_bids = mne.Epochs(\n",
    "                raw_bids,\n",
    "                events=events_filt,\n",
    "                event_id=filtered_event_id,\n",
    "                tmin=tmin / 1000.0,\n",
    "                tmax=tmax / 1000.0,\n",
    "                baseline=None,\n",
    "                preload=True,\n",
    "            )\n",
    "\n",
    "            picks_eeg = mne.pick_types(epochs_bids.info, eeg=True, eog=False, misc=False)\n",
    "            epochs_bids = epochs_bids.pick(picks_eeg)\n",
    "\n",
    "            # metadata aligned to events_filt\n",
    "            meta = pd.DataFrame({\n",
    "                \"sample\": events_filt[:, 0].astype(int),\n",
    "                \"trial_type\": [etype] * len(events_filt),\n",
    "            })\n",
    "            meta[\"onset\"] = meta[\"sample\"] / sfreq\n",
    "\n",
    "            eeg_bids = TimeSeries.from_mne_epochs(epochs_bids, meta)\n",
    "            eeg_bids = eeg_bids.assign_coords(time=eeg_bids[\"time\"] * 1000.0)\n",
    "            eeg_bids[\"time\"].attrs[\"units\"] = \"ms\"\n",
    "\n",
    "            # --------------------------\n",
    "            # Compare\n",
    "            # --------------------------\n",
    "            res = compare_eeg_sources(\n",
    "                eeg_dict={\"BIDS\": eeg_bids, \"CMLReader\": eeg_cml},\n",
    "                subject=sub,\n",
    "                experiment=exp,\n",
    "                session=sess,\n",
    "                options=[\"strip_metadata\", \"compare_raw_signals\", \"compare_time_coords\"],\n",
    "            )\n",
    "\n",
    "            # append dfs; add event type column so you can stratify later\n",
    "            if res.get(\"df_raw\") is not None and not res[\"df_raw\"].empty:\n",
    "                df = res[\"df_raw\"].copy()\n",
    "                df[\"event_type\"] = etype\n",
    "                all_raw.append(df)\n",
    "\n",
    "            if res.get(\"df_raw_summary\") is not None and not res[\"df_raw_summary\"].empty:\n",
    "                df = res[\"df_raw_summary\"].copy()\n",
    "                df[\"event_type\"] = etype\n",
    "                all_raw_summary.append(df)\n",
    "\n",
    "            if res.get(\"df_time\") is not None and not res[\"df_time\"].empty:\n",
    "                df = res[\"df_time\"].copy()\n",
    "                df[\"event_type\"] = etype\n",
    "                all_time.append(df)\n",
    "\n",
    "            per_type_status.append((etype, \"ok\", \"\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            per_type_status.append((etype, \"fail\", repr(e)))\n",
    "\n",
    "        finally:\n",
    "            # free big objects per type\n",
    "            for name in (\"epochs_bids\", \"eeg_bids\", \"eeg_cml\", \"res\", \"events_filt\", \"meta\"):\n",
    "                if name in locals():\n",
    "                    try:\n",
    "                        del locals()[name]\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            gc.collect()\n",
    "\n",
    "    # done with BIDS raw\n",
    "    try:\n",
    "        raw_bids.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    del raw_bids\n",
    "    gc.collect()\n",
    "\n",
    "    # concatenate and save\n",
    "    df_raw_all = pd.concat(all_raw, ignore_index=True) if all_raw else pd.DataFrame()\n",
    "    df_raw_summary_all = pd.concat(all_raw_summary, ignore_index=True) if all_raw_summary else pd.DataFrame()\n",
    "    df_time_all = pd.concat(all_time, ignore_index=True) if all_time else pd.DataFrame()\n",
    "\n",
    "    df_raw_all.to_csv(out_raw, index=False)\n",
    "    df_raw_summary_all.to_csv(out_raw_summary, index=False)\n",
    "    df_time_all.to_csv(out_time, index=False)\n",
    "\n",
    "    return {\n",
    "        \"df_raw\": df_raw_all,\n",
    "        \"df_raw_summary\": df_raw_summary_all,\n",
    "        \"df_time\": df_time_all,\n",
    "        \"per_type_status\": pd.DataFrame(per_type_status, columns=[\"event_type\", \"status\", \"detail\"]),\n",
    "        \"paths\": expected,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65633b27-823e-42b8-adfe-1589f8f78f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "# REL_START, REL_STOP = 200, 3000\n",
    "# BUFFER_MS = 1000\n",
    "# tmin = (-BUFFER_MS)\n",
    "# tmax = ((REL_STOP + BUFFER_MS))\n",
    "# results = process_epoched_signals(\"LTP606\", \"ValueCourier\", 0, [\"WORD\"], tmin, tmax, bids_root, \"raw_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "163e54aa-2cc4-4e5f-824c-fd33d94e66bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for zrentala is 51618\n",
      "{'dashboard_address': ':51618'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN zrentala@rhino2.psych.upenn.edu -L 8000:192.168.86.104:38458` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/global/miniconda/py310_23.1.0-1/envs/workshop_311/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 51618 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38458 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = da.new_dask_client_slurm(\n",
    "    job_name=\"raw_signals\",\n",
    "    memory_per_job=\"100GB\",\n",
    "    max_n_jobs=20,\n",
    "    queue=\"RAM\",\n",
    "    local_directory=\"~/scratch\",\n",
    "    log_directory=os.path.expanduser(\"~/log_directory\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31fd109b-7922-4848-a344-e5d4490766d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recognition</th>\n",
       "      <th>all_events</th>\n",
       "      <th>contacts</th>\n",
       "      <th>experiment</th>\n",
       "      <th>import_type</th>\n",
       "      <th>localization</th>\n",
       "      <th>math_events</th>\n",
       "      <th>montage</th>\n",
       "      <th>original_experiment</th>\n",
       "      <th>original_session</th>\n",
       "      <th>pairs</th>\n",
       "      <th>ps4_events</th>\n",
       "      <th>session</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_alias</th>\n",
       "      <th>system_version</th>\n",
       "      <th>task_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>LTP063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP063/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ltpFR</td>\n",
       "      <td>build</td>\n",
       "      <td>0</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>LTP074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>protocols/ltp/subjects/LTP074/experiments/ltpF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Recognition                                         all_events contacts  \\\n",
       "0           NaN  protocols/ltp/subjects/LTP063/experiments/ltpF...      NaN   \n",
       "1           NaN  protocols/ltp/subjects/LTP063/experiments/ltpF...      NaN   \n",
       "2           NaN  protocols/ltp/subjects/LTP063/experiments/ltpF...      NaN   \n",
       "3           NaN  protocols/ltp/subjects/LTP063/experiments/ltpF...      NaN   \n",
       "4           NaN  protocols/ltp/subjects/LTP063/experiments/ltpF...      NaN   \n",
       "..          ...                                                ...      ...   \n",
       "180         NaN  protocols/ltp/subjects/LTP074/experiments/ltpF...      NaN   \n",
       "181         NaN  protocols/ltp/subjects/LTP074/experiments/ltpF...      NaN   \n",
       "182         NaN  protocols/ltp/subjects/LTP074/experiments/ltpF...      NaN   \n",
       "183         NaN  protocols/ltp/subjects/LTP074/experiments/ltpF...      NaN   \n",
       "184         NaN  protocols/ltp/subjects/LTP074/experiments/ltpF...      NaN   \n",
       "\n",
       "    experiment import_type  localization  \\\n",
       "0        ltpFR       build             0   \n",
       "1        ltpFR       build             0   \n",
       "2        ltpFR       build             0   \n",
       "3        ltpFR       build             0   \n",
       "4        ltpFR       build             0   \n",
       "..         ...         ...           ...   \n",
       "180      ltpFR       build             0   \n",
       "181      ltpFR       build             0   \n",
       "182      ltpFR       build             0   \n",
       "183      ltpFR       build             0   \n",
       "184      ltpFR       build             0   \n",
       "\n",
       "                                           math_events  montage  \\\n",
       "0    protocols/ltp/subjects/LTP063/experiments/ltpF...        0   \n",
       "1    protocols/ltp/subjects/LTP063/experiments/ltpF...        0   \n",
       "2    protocols/ltp/subjects/LTP063/experiments/ltpF...        0   \n",
       "3    protocols/ltp/subjects/LTP063/experiments/ltpF...        0   \n",
       "4    protocols/ltp/subjects/LTP063/experiments/ltpF...        0   \n",
       "..                                                 ...      ...   \n",
       "180  protocols/ltp/subjects/LTP074/experiments/ltpF...        0   \n",
       "181  protocols/ltp/subjects/LTP074/experiments/ltpF...        0   \n",
       "182  protocols/ltp/subjects/LTP074/experiments/ltpF...        0   \n",
       "183  protocols/ltp/subjects/LTP074/experiments/ltpF...        0   \n",
       "184  protocols/ltp/subjects/LTP074/experiments/ltpF...        0   \n",
       "\n",
       "    original_experiment original_session pairs ps4_events  session subject  \\\n",
       "0                   NaN                0   NaN        NaN        0  LTP063   \n",
       "1                   NaN                1   NaN        NaN        1  LTP063   \n",
       "2                   NaN               10   NaN        NaN       10  LTP063   \n",
       "3                   NaN               11   NaN        NaN       11  LTP063   \n",
       "4                   NaN               12   NaN        NaN       12  LTP063   \n",
       "..                  ...              ...   ...        ...      ...     ...   \n",
       "180                 NaN                5   NaN        NaN        5  LTP074   \n",
       "181                 NaN                6   NaN        NaN        6  LTP074   \n",
       "182                 NaN                7   NaN        NaN        7  LTP074   \n",
       "183                 NaN                8   NaN        NaN        8  LTP074   \n",
       "184                 NaN                9   NaN        NaN        9  LTP074   \n",
       "\n",
       "    subject_alias  system_version  \\\n",
       "0          LTP063             NaN   \n",
       "1          LTP063             NaN   \n",
       "2          LTP063             NaN   \n",
       "3          LTP063             NaN   \n",
       "4          LTP063             NaN   \n",
       "..            ...             ...   \n",
       "180        LTP074             NaN   \n",
       "181        LTP074             NaN   \n",
       "182        LTP074             NaN   \n",
       "183        LTP074             NaN   \n",
       "184        LTP074             NaN   \n",
       "\n",
       "                                           task_events  \n",
       "0    protocols/ltp/subjects/LTP063/experiments/ltpF...  \n",
       "1    protocols/ltp/subjects/LTP063/experiments/ltpF...  \n",
       "2    protocols/ltp/subjects/LTP063/experiments/ltpF...  \n",
       "3    protocols/ltp/subjects/LTP063/experiments/ltpF...  \n",
       "4    protocols/ltp/subjects/LTP063/experiments/ltpF...  \n",
       "..                                                 ...  \n",
       "180  protocols/ltp/subjects/LTP074/experiments/ltpF...  \n",
       "181  protocols/ltp/subjects/LTP074/experiments/ltpF...  \n",
       "182  protocols/ltp/subjects/LTP074/experiments/ltpF...  \n",
       "183  protocols/ltp/subjects/LTP074/experiments/ltpF...  \n",
       "184  protocols/ltp/subjects/LTP074/experiments/ltpF...  \n",
       "\n",
       "[185 rows x 17 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_subjects = 10\n",
    "# experiments = [\"ValueCourier\", \"ltpFR\", \"ltpFR2\", \"VFFR\"]\n",
    "experiments = [\"ltpFR\"]\n",
    "\n",
    "subjects_to_exclude = {\"LTP001\", \"LTP9992\", \"LTP9993\"}  # <-- your list here\n",
    "\n",
    "df = cml.get_data_index()\n",
    "\n",
    "df_exp = df[df[\"experiment\"].isin(experiments)].copy()\n",
    "\n",
    "# remove excluded subjects up front\n",
    "df_exp = df_exp[~df_exp[\"subject\"].isin(subjects_to_exclude)].copy()\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for exp in experiments:\n",
    "    df_this = df_exp[df_exp[\"experiment\"] == exp]\n",
    "\n",
    "    subjects = (\n",
    "        df_this[\"subject\"]\n",
    "        .drop_duplicates()\n",
    "        .sort_values()      # deterministic\n",
    "        .head(max_subjects)\n",
    "    )\n",
    "\n",
    "    df_keep = df_this[df_this[\"subject\"].isin(subjects)].copy()\n",
    "    dfs.append(df_keep)\n",
    "\n",
    "df_subset = pd.concat(dfs, ignore_index=True)\n",
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4938d1c-5be2-45b7-b3e2-2d58bb568103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmlreader = cml.CMLReader(subject='LTP063', experiment=\"ltpFR\", session=0)\n",
    "# eeg = cmlreader.load_eeg().to_ptsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5064ecf8-bf63-4705-adb5-5179f60fa556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mne_bids import get_entity_vals, BIDSPath\n",
    "\n",
    "# bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "# out_path = \"raw_results/\"\n",
    "# os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# REL_STOP = 3000\n",
    "# BUFFER_MS = 1000\n",
    "# tmin = -BUFFER_MS\n",
    "# tmax = REL_STOP + BUFFER_MS\n",
    "# evs_type = None\n",
    "\n",
    "# subjects = get_entity_vals(bids_root, \"subject\")\n",
    "# print(subjects)\n",
    "# # tasks = get_entity_vals(bids_root, \"task\")         # <-- experiment == task in BIDS\n",
    "# tasks = [\"ltpFR2\", \"ltpFR\", \"ValueCourier\", \"VFFR\"]\n",
    "# sessions_all = get_entity_vals(bids_root, \"session\")\n",
    "\n",
    "# futures = []\n",
    "\n",
    "# for sub in subjects:\n",
    "#     # only sessions that exist for this subject (directory-based)\n",
    "#     ses_for_sub = [\n",
    "#         ses for ses in sessions_all\n",
    "#         if os.path.isdir(os.path.join(bids_root, f\"sub-{sub}\", f\"ses-{ses}\"))\n",
    "#     ]\n",
    "\n",
    "#     # only tasks that exist for this subject+session (file-based)\n",
    "#     for ses in ses_for_sub:\n",
    "#         # print(ses)\n",
    "#         for task in tasks:\n",
    "#             bids_path = BIDSPath(\n",
    "#                 subject=sub, session=str(ses), task=task,\n",
    "#                 datatype=\"eeg\", root=bids_root\n",
    "#             )\n",
    "\n",
    "#             # skip nonexistent combinations (no EEG file)\n",
    "#             matches = bids_path.match()\n",
    "#             if len(matches) == 0:\n",
    "#                 continue\n",
    "#             print(f\"{sub} {task} {sess} {bids_root} {out_path}\")\n",
    "#             futures.append(client.submit(\n",
    "#                 process_epoched_signals, sub, task, ses, evs_type, tmin, tmax, bids_root, out_path\n",
    "#             ))\n",
    "#             futures.append(client.submit(\n",
    "#                 process_events, sub, task, ses, evs_type, bids_root, out_path\n",
    "#             ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6c17f29-cf09-47b5-9dca-81dcfaca67fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get futures\n",
    "bids_root = \"/home1/maint/LTP_BIDS/\"\n",
    "subjects = get_entity_vals(bids_root, \"subject\")\n",
    "out_path = \"raw_results_type/\"\n",
    "futures = []\n",
    "REL_START, REL_STOP = 200, 1000\n",
    "BUFFER_MS = 1000\n",
    "# evs_type = [\"WORD\"]\n",
    "evs_type = None\n",
    "tmin = (-BUFFER_MS)\n",
    "tmax = ((REL_STOP + BUFFER_MS))\n",
    "future_meta = {} \n",
    "futures_eeg = []\n",
    "for i, row in df_subset.iterrows():\n",
    "    sub = row[\"subject\"]\n",
    "    exp = row[\"experiment\"]\n",
    "    sess = row[\"session\"]\n",
    "    # try:\n",
    "    #     process_epoched_signals_by_type(sub, exp, sess, evs_type, tmin, tmax, bids_root, out_path, verbose=True)\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    fut = client.submit(\n",
    "        process_epoched_signals_by_type,\n",
    "        sub, exp, sess, evs_type, tmin, tmax, bids_root, out_path\n",
    "    )\n",
    "\n",
    "    futures_eeg.append(fut)\n",
    "    future_meta[fut.key] = (sub, exp, sess)\n",
    "    # if i < 15:\n",
    "    #     break\n",
    "\n",
    "# for sub in subjects:\n",
    "#     subject_root = os.path.join(bids_root, f\"sub-{sub}\")\n",
    "#     experiments = get_entity_vals(subject_root, \"experiment\")\n",
    "#     print(experiments)\n",
    "#     sessions = get_entity_vals(subject_root, \"session\")\n",
    "#     # futures.extend([client.submit(process_raw_signals, sub, \"ValueCourier\", sess, bids_root,out_path) for sess in sessions])\n",
    "#     futures.extend([client.submit(process_epoched_signals, sub, exp, sess, evs_type, tmin, tmax, bids_root, out_path)for sess in sessions for exp in experiments])\n",
    "#     futures.extend([client.submit(process_events, sub, exp, sess, evs_type, bids_root, out_path) for sess in sessions])\n",
    "#     break\n",
    "#     # process_epoched_signals(sub, exp, sess, evs_types, tmin, tmax, bids_root, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4d99f01-8fb7-4233-99af-d6de3ccf40c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAIL] LTP063 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-1/eeg'  (1)\n",
      "[FAIL] LTP063 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-0/eeg'  (2)\n",
      "[FAIL] LTP063 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-18/eeg'  (3)\n",
      "[FAIL] LTP063 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-19/eeg'  (4)\n",
      "[FAIL] LTP063 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-11/eeg'  (5)\n",
      "[FAIL] LTP063 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-2/eeg'  (6)\n",
      "[FAIL] LTP063 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-10/eeg'  (7)\n",
      "[FAIL] LTP063 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-3/eeg'  (8)\n",
      "[FAIL] LTP063 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-13/eeg'  (9)\n",
      "[FAIL] LTP063 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-4/eeg'  (10)\n",
      "[FAIL] LTP063 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-5/eeg'  (11)\n",
      "[FAIL] LTP063 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-6/eeg'  (12)\n",
      "[FAIL] LTP063 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-12/eeg'  (13)\n",
      "[FAIL] LTP063 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-7/eeg'  (14)\n",
      "[FAIL] LTP064 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-0/eeg'  (15)\n",
      "[FAIL] LTP063 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-8/eeg'  (16)\n",
      "[FAIL] LTP063 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-9/eeg'  (17)\n",
      "[FAIL] LTP064 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-1/eeg'  (18)\n",
      "[FAIL] LTP064 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-11/eeg'  (19)\n",
      "[FAIL] LTP064 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-10/eeg'  (20)\n",
      "[FAIL] LTP064 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-14/eeg'  (21)\n",
      "[FAIL] LTP064 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-12/eeg'  (22)\n",
      "[FAIL] LTP064 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-13/eeg'  (23)\n",
      "[FAIL] LTP064 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-15/eeg'  (24)\n",
      "[FAIL] LTP064 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-16/eeg'  (25)\n",
      "[FAIL] LTP064 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-17/eeg'  (26)\n",
      "[FAIL] LTP064 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-18/eeg'  (27)\n",
      "[FAIL] LTP064 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-19/eeg'  (28)\n",
      "[FAIL] LTP064 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-2/eeg'  (29)\n",
      "[FAIL] LTP064 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-3/eeg'  (30)\n",
      "[FAIL] LTP064 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-4/eeg'  (31)\n",
      "[FAIL] LTP064 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-5/eeg'  (32)\n",
      "[FAIL] LTP063 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-15/eeg'  (33)\n",
      "[FAIL] LTP064 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-6/eeg'  (34)\n",
      "[FAIL] LTP064 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-7/eeg'  (35)\n",
      "[FAIL] LTP063 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-14/eeg'  (36)\n",
      "[FAIL] LTP064 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-8/eeg'  (37)\n",
      "[FAIL] LTP064 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP064/ses-9/eeg'  (38)\n",
      "[FAIL] LTP065 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-0/eeg'  (39)\n",
      "[FAIL] LTP063 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-17/eeg'  (40)\n",
      "[FAIL] LTP065 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-10/eeg'  (41)\n",
      "[FAIL] LTP065 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-1/eeg'  (42)\n",
      "[FAIL] LTP065 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-12/eeg'  (43)\n",
      "[FAIL] LTP065 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-11/eeg'  (44)\n",
      "[FAIL] LTP063 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP063/ses-16/eeg'  (45)\n",
      "[FAIL] LTP065 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-14/eeg'  (46)\n",
      "[FAIL] LTP065 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-16/eeg'  (47)\n",
      "[FAIL] LTP065 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-13/eeg'  (48)\n",
      "[FAIL] LTP065 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-15/eeg'  (49)\n",
      "[FAIL] LTP065 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-17/eeg'  (50)\n",
      "[FAIL] LTP065 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-19/eeg'  (51)\n",
      "[FAIL] LTP065 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-2/eeg'  (52)\n",
      "[FAIL] LTP065 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-18/eeg'  (53)\n",
      "[FAIL] LTP065 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-4/eeg'  (54)\n",
      "[FAIL] LTP065 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-3/eeg'  (55)\n",
      "[FAIL] LTP065 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-6/eeg'  (56)\n",
      "[FAIL] LTP065 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-5/eeg'  (57)\n",
      "[FAIL] LTP065 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-9/eeg'  (58)\n",
      "[FAIL] LTP065 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-8/eeg'  (59)\n",
      "[FAIL] LTP066 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-1/eeg'  (60)\n",
      "[FAIL] LTP066 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-0/eeg'  (61)\n",
      "[FAIL] LTP066 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-13/eeg'  (62)\n",
      "[FAIL] LTP066 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-12/eeg'  (63)\n",
      "[FAIL] LTP066 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-14/eeg'  (64)\n",
      "[FAIL] LTP065 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP065/ses-7/eeg'  (65)\n",
      "[FAIL] LTP066 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-17/eeg'  (66)\n",
      "[FAIL] LTP066 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-16/eeg'  (67)\n",
      "[FAIL] LTP066 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-18/eeg'  (68)\n",
      "[FAIL] LTP066 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-19/eeg'  (69)\n",
      "[FAIL] LTP066 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-10/eeg'  (70)\n",
      "[FAIL] LTP066 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-11/eeg'  (71)\n",
      "[FAIL] LTP066 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-2/eeg'  (72)\n",
      "[FAIL] LTP066 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-3/eeg'  (73)\n",
      "[FAIL] LTP066 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-5/eeg'  (74)\n",
      "[FAIL] LTP066 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-15/eeg'  (75)\n",
      "[FAIL] LTP066 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-4/eeg'  (76)\n",
      "[FAIL] LTP066 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-6/eeg'  (77)\n",
      "[FAIL] LTP066 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-8/eeg'  (78)\n",
      "[FAIL] LTP066 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-7/eeg'  (79)\n",
      "[FAIL] LTP067 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-0/eeg'  (80)\n",
      "[FAIL] LTP066 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP066/ses-9/eeg'  (81)\n",
      "[FAIL] LTP067 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-1/eeg'  (82)\n",
      "[FAIL] LTP067 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-11/eeg'  (83)\n",
      "[FAIL] LTP067 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-10/eeg'  (84)\n",
      "[FAIL] LTP067 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-12/eeg'  (85)\n",
      "[FAIL] LTP067 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-14/eeg'  (86)\n",
      "[FAIL] LTP067 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-13/eeg'  (87)\n",
      "[FAIL] LTP067 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-15/eeg'  (88)\n",
      "[FAIL] LTP067 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-16/eeg'  (89)\n",
      "[FAIL] LTP067 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-17/eeg'  (90)\n",
      "[FAIL] LTP067 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-19/eeg'  (91)\n",
      "[FAIL] LTP067 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-2/eeg'  (92)\n",
      "[FAIL] LTP067 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-18/eeg'  (93)\n",
      "[FAIL] LTP067 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-3/eeg'  (94)\n",
      "[FAIL] LTP067 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-4/eeg'  (95)\n",
      "[FAIL] LTP067 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-5/eeg'  (96)\n",
      "[FAIL] LTP067 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-6/eeg'  (97)\n",
      "[FAIL] LTP067 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-7/eeg'  (98)\n",
      "[FAIL] LTP068 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP068/ses-1/eeg'  (99)\n",
      "[FAIL] LTP067 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-9/eeg'  (100)\n",
      "[FAIL] LTP068 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP068/ses-0/eeg'  (101)\n",
      "[FAIL] LTP067 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP067/ses-8/eeg'  (102)\n",
      "[FAIL] LTP068 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP068/ses-2/eeg'  (103)\n",
      "[FAIL] LTP068 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP068/ses-4/eeg'  (104)\n",
      "[FAIL] LTP069 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-10/eeg'  (105)\n",
      "[FAIL] LTP069 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-1/eeg'  (106)\n",
      "[FAIL] LTP069 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-0/eeg'  (107)\n",
      "[FAIL] LTP068 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP068/ses-3/eeg'  (108)\n",
      "[FAIL] LTP069 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-11/eeg'  (109)\n",
      "[FAIL] LTP069 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-15/eeg'  (110)\n",
      "[FAIL] LTP069 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-12/eeg'  (111)\n",
      "[FAIL] LTP069 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-14/eeg'  (112)\n",
      "[FAIL] LTP069 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-13/eeg'  (113)\n",
      "[FAIL] LTP069 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-17/eeg'  (114)\n",
      "[FAIL] LTP069 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-18/eeg'  (115)\n",
      "[FAIL] LTP069 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-16/eeg'  (116)\n",
      "[FAIL] LTP069 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-2/eeg'  (117)\n",
      "[FAIL] LTP069 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-19/eeg'  (118)\n",
      "[FAIL] LTP069 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-3/eeg'  (119)\n",
      "[FAIL] LTP069 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-4/eeg'  (120)\n",
      "[FAIL] LTP069 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-5/eeg'  (121)\n",
      "[FAIL] LTP069 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-6/eeg'  (122)\n",
      "[FAIL] LTP069 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-7/eeg'  (123)\n",
      "[FAIL] LTP069 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-8/eeg'  (124)\n",
      "[FAIL] LTP070 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-0/eeg'  (125)\n",
      "[FAIL] LTP070 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-1/eeg'  (126)\n",
      "[FAIL] LTP069 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP069/ses-9/eeg'  (127)\n",
      "[FAIL] LTP070 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-12/eeg'  (128)\n",
      "[FAIL] LTP070 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-13/eeg'  (129)\n",
      "[FAIL] LTP070 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-15/eeg'  (130)\n",
      "[FAIL] LTP070 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-16/eeg'  (131)\n",
      "[FAIL] LTP070 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-14/eeg'  (132)\n",
      "[FAIL] LTP070 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-19/eeg'  (133)\n",
      "[FAIL] LTP070 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-2/eeg'  (134)\n",
      "[FAIL] LTP070 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-3/eeg'  (135)\n",
      "[FAIL] LTP070 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-4/eeg'  (136)\n",
      "[FAIL] LTP070 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-5/eeg'  (137)\n",
      "[FAIL] LTP070 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-9/eeg'  (138)\n",
      "[FAIL] LTP070 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-8/eeg'  (139)\n",
      "[FAIL] LTP073 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-0/eeg'  (140)\n",
      "[FAIL] LTP073 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-1/eeg'  (141)\n",
      "[FAIL] LTP073 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-10/eeg'  (142)\n",
      "[FAIL] LTP073 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-16/eeg'  (143)\n",
      "[FAIL] LTP073 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-15/eeg'  (144)\n",
      "[FAIL] LTP073 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-17/eeg'  (145)\n",
      "[FAIL] LTP073 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-18/eeg'  (146)\n",
      "[FAIL] LTP073 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-19/eeg'  (147)\n",
      "[FAIL] LTP073 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-2/eeg'  (148)\n",
      "[FAIL] LTP073 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-5/eeg'  (149)\n",
      "[FAIL] LTP073 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-6/eeg'  (150)\n",
      "[FAIL] LTP074 | ltpFR | 1  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-1/eeg'  (151)\n",
      "[FAIL] LTP073 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-7/eeg'  (152)\n",
      "[FAIL] LTP074 | ltpFR | 0  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-0/eeg'  (153)\n",
      "[FAIL] LTP074 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-10/eeg'  (154)\n",
      "[FAIL] LTP074 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-14/eeg'  (155)\n",
      "[FAIL] LTP074 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-11/eeg'  (156)\n",
      "[FAIL] LTP074 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-12/eeg'  (157)\n",
      "[FAIL] LTP074 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-13/eeg'  (158)\n",
      "[FAIL] LTP074 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-17/eeg'  (159)\n",
      "[FAIL] LTP074 | ltpFR | 15  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-15/eeg'  (160)\n",
      "[FAIL] LTP074 | ltpFR | 16  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-16/eeg'  (161)\n",
      "[FAIL] LTP074 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-18/eeg'  (162)\n",
      "[FAIL] LTP074 | ltpFR | 19  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-19/eeg'  (163)\n",
      "[FAIL] LTP074 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-6/eeg'  (164)\n",
      "[FAIL] LTP074 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-7/eeg'  (165)\n",
      "[FAIL] LTP074 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-8/eeg'  (166)\n",
      "[FAIL] LTP074 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-9/eeg'  (167)\n",
      "[FAIL] LTP070 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-11/eeg'  (168)\n",
      "[FAIL] LTP070 | ltpFR | 7  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-7/eeg'  (169)\n",
      "[FAIL] LTP070 | ltpFR | 10  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-10/eeg'  (170)\n",
      "[FAIL] LTP070 | ltpFR | 6  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-6/eeg'  (171)\n",
      "[FAIL] LTP070 | ltpFR | 18  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-18/eeg'  (172)\n",
      "[FAIL] LTP070 | ltpFR | 17  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP070/ses-17/eeg'  (173)\n",
      "[FAIL] LTP073 | ltpFR | 12  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-12/eeg'  (174)\n",
      "[FAIL] LTP073 | ltpFR | 14  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-14/eeg'  (175)\n",
      "[FAIL] LTP073 | ltpFR | 11  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-11/eeg'  (176)\n",
      "[FAIL] LTP073 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-4/eeg'  (177)\n",
      "[FAIL] LTP073 | ltpFR | 13  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-13/eeg'  (178)\n",
      "[FAIL] LTP073 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-3/eeg'  (179)\n",
      "[FAIL] LTP074 | ltpFR | 3  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-3/eeg'  (180)\n",
      "[FAIL] LTP074 | ltpFR | 5  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-5/eeg'  (181)\n",
      "[FAIL] LTP073 | ltpFR | 9  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-9/eeg'  (182)\n",
      "[FAIL] LTP074 | ltpFR | 2  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-2/eeg'  (183)\n",
      "[FAIL] LTP074 | ltpFR | 4  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP074/ses-4/eeg'  (184)\n",
      "[FAIL] LTP073 | ltpFR | 8  -> [Errno 2] No such file or directory: '/home1/maint/LTP_BIDS/sub-LTP073/ses-8/eeg'  (185)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m         n_fail \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[FAIL] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msess\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_fail\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m df_raw_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_df_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m df_raw_summary_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_df_raw_summary, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m df_time_all \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_df_time, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/global/miniconda/py310_23.1.0-1/envs/workshop_311/lib/python3.11/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/usr/global/miniconda/py310_23.1.0-1/envs/workshop_311/lib/python3.11/site-packages/pandas/core/reshape/concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    426\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# run futures \n",
    "from dask.distributed import as_completed\n",
    "\n",
    "all_df_raw = []\n",
    "all_df_raw_summary = []\n",
    "all_df_time = []\n",
    "all_df_behavior_summary = []\n",
    "# all_df_behavior_column_summary = []\n",
    "# all_df_behavior_mismatches = []\n",
    "# all_eegs_std = []\n",
    "\n",
    "n_done, n_fail = 0, 0\n",
    "\n",
    "for fut in as_completed(futures_eeg):\n",
    "    sub, exp, sess = future_meta.get(fut.key, (\"<unknown>\", \"<unknown>\", \"<unknown>\"))\n",
    "\n",
    "    try:\n",
    "        out = fut.result()\n",
    "\n",
    "        if out.get(\"skipped\"):\n",
    "            print(f\"[SKIP] {sub} | {exp} | {sess}\")\n",
    "            continue\n",
    "\n",
    "        if out[\"df_raw\"] is not None and not out[\"df_raw\"].empty:\n",
    "            all_df_raw.append(out[\"df_raw\"])\n",
    "\n",
    "        if out[\"df_raw_summary\"] is not None and not out[\"df_raw_summary\"].empty:\n",
    "            all_df_raw_summary.append(out[\"df_raw_summary\"])\n",
    "\n",
    "        if out[\"df_time\"] is not None and not out[\"df_time\"].empty:\n",
    "            all_df_time.append(out[\"df_time\"])\n",
    "\n",
    "        n_done += 1\n",
    "        print(f\"[DONE] {sub} | {exp} | {sess}  ({n_done})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        n_fail += 1\n",
    "        print(f\"[FAIL] {sub} | {exp} | {sess}  -> {e}  ({n_fail})\")\n",
    "df_raw_all = pd.concat(all_df_raw, ignore_index=True)\n",
    "df_raw_summary_all = pd.concat(all_df_raw_summary, ignore_index=True)\n",
    "df_time_all = pd.concat(all_df_time, ignore_index=True)\n",
    "# df_behavior_summary_all = pd.concat(all_df_behavior_summary, ignore_index=True)\n",
    "\n",
    "# df_raw_all.to_csv(f\"{out_path}df_raw_all.csv\", index=False)\n",
    "# df_raw_summary_all.to_csv(f\"{out_path}df_raw_summary_all.csv\", index=False)\n",
    "# df_time_all.to_csv(f\"{out_path}df_time_all.csv\", index=False)\n",
    "# df_behavior_summary_all.to_csv(f\"{out_path}df_behavior_summary_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f8376-2f07-4557-9672-da8c6e966d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_beh = []\n",
    "for i, row in df_subset.iterrows():\n",
    "    sub = row[\"subject\"]\n",
    "    exp = row[\"experiment\"]\n",
    "    sess = row[\"session\"]\n",
    "    futures_beh.append(client.submit(process_events, sub, exp, sess, evs_type, bids_root, out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa33d7-31e8-49fe-ae48-2b0398410ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run futures \n",
    "from dask.distributed import as_completed\n",
    "\n",
    "all_df_behavior_summary = []\n",
    "\n",
    "n_done, n_fail = 0, 0\n",
    "\n",
    "for fut in as_completed(futures_beh):\n",
    "    try:\n",
    "        out = fut.result()\n",
    "        \n",
    "        if out[\"df_behavior_summary\"] is not None and not out[\"df_behavior_summary\"].empty:\n",
    "            all_df_behavior_summary.append(out[\"df_behavior_summary\"])\n",
    "\n",
    "        # Append eeg_std list\n",
    "        # all_eegs_std.extend(out[\"eegs_std\"])\n",
    "\n",
    "        n_done += 1\n",
    "        print(f\"[DONE] {n_done}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        n_fail += 1\n",
    "        print(f\"[ERR] Future failed ({n_fail} fails): {e}\")\n",
    "df_behavior_summary_all = pd.concat(all_df_behavior_summary, ignore_index=True)\n",
    "\n",
    "df_behavior_summary_all.to_csv(f\"{out_path}df_behavior_summary_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ecba4-f06f-4bd4-a561-2a03a7091649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "out_path = \"raw_results/\"\n",
    "df_raw_filenames = []\n",
    "df_raw_summary_filenames = []\n",
    "df_time_filenames = []\n",
    "df_behavior_summary_filenames = []\n",
    "\n",
    "for dirpath, _, filenames in os.walk(out_path):\n",
    "    for f in filenames:\n",
    "        full_path = os.path.join(dirpath, f)\n",
    "        \n",
    "        # Categorize based on string patterns\n",
    "        if f.startswith('df_raw_summary_') and f.endswith('.csv'):\n",
    "            df_raw_summary_filenames.append(full_path)\n",
    "        elif f.startswith('df_raw_') and f.endswith('.csv'):\n",
    "            df_raw_filenames.append(full_path)\n",
    "        elif f.startswith('df_time_') and f.endswith('.csv'):\n",
    "            df_time_filenames.append(full_path)\n",
    "        elif f.startswith('df_behavior_summary_') and f.endswith('.csv'):\n",
    "            df_behavior_summary_filenames.append(full_path)\n",
    "            \n",
    "def load_and_concat(file_list):\n",
    "    if not file_list:\n",
    "        return pd.DataFrame()  # Return empty DF if no files found\n",
    "    # Read each CSV and combine them into one\n",
    "    return pd.concat([pd.read_csv(f) for f in file_list], ignore_index=True)\n",
    "\n",
    "# Create the 3 distinct DataFrames\n",
    "df_raw_all = load_and_concat(df_raw_filenames)\n",
    "df_raw_summary_all = load_and_concat(df_raw_summary_filenames)\n",
    "df_time_all = load_and_concat(df_time_filenames)\n",
    "df_behavior_summary_all = load_and_concat(df_behavior_summary_filenames)\n",
    "\n",
    "\n",
    "# df_raw_all.to_csv(\"df_raw_all.csv\", index=False)\n",
    "# df_raw_summary_all.to_csv(\"df_raw_summary_all.csv\", index=False)\n",
    "# df_time_all.to_csv(\"df_time_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90af5d4-22b0-499f-88d7-e8ceb9d5bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mean and std difference\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "comparisons = df_time_all['comparison'].unique()\n",
    "subjects = df_time_all['subject'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(comparisons), figsize=(6 * len(comparisons), 5), sharex=True)\n",
    "if len(comparisons) == 1: axes = [axes]\n",
    "\n",
    "for i, comp in enumerate(comparisons):\n",
    "    ax = axes[i]\n",
    "    comp_df = df_time_all[df_time_all['comparison'] == comp]\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_df = comp_df[comp_df['subject'] == subj].sort_values('session')\n",
    "        if subj_df.empty: continue\n",
    "        \n",
    "        # Plot mean line\n",
    "        line, = ax.plot(subj_df['session'], subj_df['mean_abs_time_diff'], marker='o', label=subj)\n",
    "        \n",
    "        # Add shaded Std region\n",
    "        ax.fill_between(\n",
    "            subj_df['session'], \n",
    "            subj_df['mean_abs_time_diff'] - subj_df['std_time_diff'],\n",
    "            subj_df['mean_abs_time_diff'] + subj_df['std_time_diff'],\n",
    "            color=line.get_color(), \n",
    "            alpha=0.15\n",
    "        )\n",
    "    \n",
    "    ax.set_title(comp)\n",
    "    ax.set_xlabel('Session')\n",
    "    if i == 0: ax.set_ylabel('Mean Abs Time Diff ($\\pm$ Std)')\n",
    "    ax.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f62f7-3975-4686-a4ef-7b987874a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse\n",
    "fig, axes = plt.subplots(1, len(comparisons), figsize=(6 * len(comparisons), 5), sharex=True)\n",
    "if len(comparisons) == 1: axes = [axes]\n",
    "\n",
    "for i, comp in enumerate(comparisons):\n",
    "    ax = axes[i]\n",
    "    comp_df = df_time_all[df_time_all['comparison'] == comp]\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_df = comp_df[comp_df['subject'] == subj].sort_values('session')\n",
    "        if subj_df.empty: continue\n",
    "        \n",
    "        # Plot mean line\n",
    "        line, = ax.plot(subj_df['session'], subj_df['mse_time'], marker='o', label=subj)\n",
    "        \n",
    "#         # Add shaded Std region\n",
    "#         ax.fill_between(\n",
    "#             subj_df['session'], \n",
    "#             subj_df['mean_abs_time_diff'] - subj_df['std_time_diff'],\n",
    "#             subj_df['mean_abs_time_diff'] + subj_df['std_time_diff'],\n",
    "#             color=line.get_color(), \n",
    "#             alpha=0.15\n",
    "#         )\n",
    "    \n",
    "    ax.set_title(comp)\n",
    "    ax.set_xlabel('Session')\n",
    "    if i == 0: ax.set_ylabel('MSE Time ($\\pm$ Std)')\n",
    "    ax.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e7bfd-5e91-4c13-9d31-660d6a625f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = df_raw_summary_all['comparison'].unique()\n",
    "subjects = df_raw_summary_all['subject'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(comparisons), figsize=(6 * len(comparisons), 5), sharex=True)\n",
    "if len(comparisons) == 1: axes = [axes]\n",
    "\n",
    "for i, comp in enumerate(comparisons):\n",
    "    ax = axes[i]\n",
    "    comp_df = df_raw_summary_all[df_raw_summary_all['comparison'] == comp]\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_df = comp_df[comp_df['subject'] == subj].sort_values('session')\n",
    "        if subj_df.empty: continue\n",
    "        \n",
    "        # Plot mean line\n",
    "        line, = ax.plot(subj_df['session'], subj_df['mean_abs_diff'], marker='o', label=subj)\n",
    "        \n",
    "        # Add shaded Std region\n",
    "        ax.fill_between(\n",
    "            subj_df['session'], \n",
    "            subj_df['mean_abs_diff'] - subj_df['std_diff'],\n",
    "            subj_df['mean_abs_diff'] + subj_df['std_diff'],\n",
    "            color=line.get_color(), \n",
    "            alpha=0.15\n",
    "        )\n",
    "    \n",
    "    ax.set_title(comp)\n",
    "    ax.set_xlabel('Session')\n",
    "    if i == 0: ax.set_ylabel('Mean Abs Signal Diff ($\\pm$ Std)')\n",
    "    ax.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d3cb3-ad83-4c9b-88de-09d3eb5042f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse\n",
    "fig, axes = plt.subplots(1, len(comparisons), figsize=(6 * len(comparisons), 5), sharex=True)\n",
    "if len(comparisons) == 1: axes = [axes]\n",
    "\n",
    "for i, comp in enumerate(comparisons):\n",
    "    ax = axes[i]\n",
    "    comp_df = df_raw_summary_all[df_raw_summary_all['comparison'] == comp]\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_df = comp_df[comp_df['subject'] == subj].sort_values('session')\n",
    "        if subj_df.empty: continue\n",
    "        \n",
    "        # Plot mean line\n",
    "        line, = ax.plot(subj_df['session'], subj_df['mse'], marker='o', label=subj)\n",
    "        \n",
    "#         # Add shaded Std region\n",
    "#         ax.fill_between(\n",
    "#             subj_df['session'], \n",
    "#             subj_df['mean_abs_time_diff'] - subj_df['std_time_diff'],\n",
    "#             subj_df['mean_abs_time_diff'] + subj_df['std_time_diff'],\n",
    "#             color=line.get_color(), \n",
    "#             alpha=0.15\n",
    "#         )\n",
    "    \n",
    "    ax.set_title(comp)\n",
    "    ax.set_xlabel('Session')\n",
    "    if i == 0: ax.set_ylabel('MSE Raw Signal ($\\pm$ Std)')\n",
    "    ax.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed4ed9-3ef6-4af8-bd59-7dc21f10457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n_channels diff\n",
    "fig, axes = plt.subplots(1, len(comparisons), figsize=(6 * len(comparisons), 5), sharex=True)\n",
    "if len(comparisons) == 1: axes = [axes]\n",
    "\n",
    "for i, comp in enumerate(comparisons):\n",
    "    ax = axes[i]\n",
    "    comp_df = df_raw_summary_all[df_raw_summary_all['comparison'] == comp]\n",
    "    \n",
    "    for subj in subjects:\n",
    "        subj_df = comp_df[comp_df['subject'] == subj].sort_values('session')\n",
    "        if subj_df.empty: continue\n",
    "        \n",
    "        # Plot mean line\n",
    "        line, = ax.plot(subj_df['session'], subj_df['n_exact_diff_channels'], marker='o', label=f\"{subj} exact\")\n",
    "        line, = ax.plot(subj_df['session'], subj_df['n_close_diff_channels'], marker='o', label=f\"{subj} close\")\n",
    "        \n",
    "#         # Add shaded Std region\n",
    "#         ax.fill_between(\n",
    "#             subj_df['session'], \n",
    "#             subj_df['mean_abs_time_diff'] - subj_df['std_time_diff'],\n",
    "#             subj_df['mean_abs_time_diff'] + subj_df['std_time_diff'],\n",
    "#             color=line.get_color(), \n",
    "#             alpha=0.15\n",
    "#         )\n",
    "    \n",
    "    ax.set_title(comp)\n",
    "    ax.set_xlabel('Session')\n",
    "    if i == 0: ax.set_ylabel('n_channels different ($\\pm$ Std)')\n",
    "    ax.legend(title='Subject')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop_311",
   "language": "python",
   "name": "workshop_311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
